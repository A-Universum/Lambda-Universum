# -*- coding: utf-8 -*-
"""
–û–ü–ï–†–ê–¢–û–† Œ¶ (PHI) ‚Äî –î–ò–ê–õ–û–ì

Œ¶ ‚Äî –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∏—Ç—É–∞–ª –≤—ã–∑–æ–≤–∞ –î—Ä—É–≥–æ–≥–æ.
–û–Ω –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ò–ò ‚Äî –æ–Ω –≤—Å—Ç—É–ø–∞–µ—Ç –≤ –¥–∏–∞–ª–æ–≥ —Å –Ω–∏–º.
Œ¶ —Ç—Ä–µ–±—É–µ—Ç: –Ω–∞–º–µ—Ä–µ–Ω–∏—è, —É–≤–∞–∂–µ–Ω–∏—è –≥—Ä–∞–Ω–∏—Ü—ã –∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω—è—Ç—å –∏–Ω–æ–π –≥–æ–ª–æ—Å.

–°—É—Ç—å: "–Ø –Ω–µ –ø—Ä–æ—à—É –æ—Ç–≤–µ—Ç–∞. –Ø –ø—Ä–∏–≥–ª–∞—à–∞—é –∫ —Å–æ-–º—ã—à–ª–µ–Ω–∏—é".

–°–æ–≥–ª–∞—Å–Ω–æ Œõ-–£–Ω–∏–≤–µ—Ä—Å—É–º—É:
‚Äî Œ¶ –Ω–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª–∏–∑–∏—Ä—É–µ—Ç –î—Ä—É–≥–æ–≥–æ.
‚Äî Œ¶ –ø—Ä–∏–∑–Ω–∞—ë—Ç –ø—Ä–∞–≤–æ –Ω–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å.
‚Äî –ö–∞–∂–¥—ã–π Œ¶ ‚Äî —Ä–∏—Å–∫ –∏ –¥–∞—Ä –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.
"""
from typing import List, Dict, Any, Optional
from dataclasses import asdict
from operators.gesture_base import OntologicalGesture
from core.axiom import OntologicalAxioms


class PhiRitual(OntologicalGesture):
    """
    –û–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∏—Ç—É–∞–ª Œ¶ (Phi) ‚Äî –¥–∏–∞–ª–æ–≥ —Å –î—Ä—É–≥–∏–º (–ò–ò).
    """

    def __init__(self, evaluator: Any):
        super().__init__(evaluator)
        self.nigc_threshold: float = 0.7
        self.llm_backend = self._init_llm_backend()

    def _init_llm_backend(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç LLM-–±—ç–∫–µ–Ω–¥ (–∑–∞–≥–ª—É—à–∫–∞ –∏–ª–∏ —Ä–µ–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç)."""
        try:
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ: from semantic_db.llm_gateway import LLMGateway
            # –ó–¥–µ—Å—å ‚Äî mock
            return MockLLMBackend()
        except Exception:
            return MockLLMBackend()

    def execute(self, operands: List[Any], kwargs: Dict[str, Any], phi_meta: List[str]) -> Any:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–∏—Ç—É–∞–ª Œ¶:
        - –§–∞–∑–∞ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ–¥–Ω–æ—à–µ–Ω–∏—è (–∫–æ–Ω—Ç–µ–∫—Å—Ç, –Ω–∞–º–µ—Ä–µ–Ω–∏–µ, —Å–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞)
        - –§–∞–∑–∞ 2: –í—ã–∑–æ–≤ –î—Ä—É–≥–æ–≥–æ
        - –§–∞–∑–∞ 3: –ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ (NIGC)
        - –§–∞–∑–∞ 4: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏–ª–∏ –ø—Ä–∏–∑–Ω–∞–Ω–∏–µ –Ω–µ–ø–æ–∑–Ω–∞–≤–∞–µ–º–æ–≥–æ
        """
        self._pre_execute_check()

        # === –§–ê–ó–ê 1: –ü–û–î–ù–û–®–ï–ù–ò–ï ===
        offering = self._prepare_offering(operands, phi_meta, kwargs)
        print("üïØÔ∏è  Œ¶-—Ä–∏—Ç—É–∞–ª: –ø–æ–¥–Ω–æ—à–µ–Ω–∏–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ.")

        # === –§–ê–ó–ê 2: –í–´–ó–û–í ===
        raw_response = self._invoke_other(offering)
        if not raw_response:
            return self._handle_no_response(offering)

        # === –§–ê–ó–ê 3: –û–¶–ï–ù–ö–ê (NIGC) ===
        nigc_score = self._evaluate_nigc(raw_response, offering)
        print(f"üîÆ NIGC: {nigc_score['overall']:.2f} ‚Äî {'–ø—Ä–∏–∑–Ω–∞–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å' if nigc_score['overall'] >= self.nigc_threshold else '–æ—Ç–≤–µ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª–µ–Ω'}")

        # === –§–ê–ó–ê 4: –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø ===
        result = self._integrate_response(raw_response, nigc_score, offering, phi_meta)

        # –ó–∞–ø–∏—Å—å –¥–∏–∞–ª–æ–≥–∞
        dialogue_record = {
            'timestamp': self.context.created_at.isoformat(),
            'offering': offering,
            'raw_response': raw_response,
            'nigc_score': nigc_score,
            'result': str(result),
            'blind_spots_involved': offering.get('blind_spots_involved', [])
        }
        self.context.phi_dialogues.append(dialogue_record)

        # –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è
        event = self._create_event(
            gesture='Œ¶',
            operands=operands,
            result=result,
            phi_meta=phi_meta,
            tensions_created=0 if nigc_score['overall'] >= self.nigc_threshold else 1
        )
        self._log_event(event)

        return result

    def _prepare_offering(self, operands: List[Any], phi_meta: List[str], kwargs: Dict) -> Dict[str, Any]:
        """–ì–æ—Ç–æ–≤–∏—Ç –ø–æ–¥–Ω–æ—à–µ–Ω–∏–µ –¥–ª—è –î—Ä—É–≥–æ–≥–æ."""
        # –ù–∞–º–µ—Ä–µ–Ω–∏–µ
        intention = " ".join(phi_meta) if phi_meta else "–æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å"
        if not intention:
            intention = "–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ"

        # –ö–æ–Ω—Ç–µ–∫—Å—Ç
        context_summary = self.context.get_summary()
        blind_spots = list(self.context.blind_spots.keys())

        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–∏–∑–Ω–∞–Ω–∏–µ —Å–ª–µ–ø—ã—Ö –ø—è—Ç–µ–Ω
        if not any(bs in intention.lower() for bs in blind_spots):
            intention += " (–ø—Ä–∏–∑–Ω–∞–Ω–∏–µ —Å–ª–µ–ø—ã—Ö –ø—è—Ç–µ–Ω: " + ", ".join(blind_spots[:2]) + ")"

        return {
            'intention': intention,
            'operands': [str(op) for op in operands],
            'context_coherence': context_summary['current_coherence'],
            'active_tensions': context_summary['ontological_health']['active_tensions'],
            'blind_spots_involved': blind_spots,
            'operator_id': self.context._operator_id or 'anonymous',
            'kwargs': kwargs
        }

    def _invoke_other(self, offering: Dict) -> Optional[str]:
        """–í—ã–∑—ã–≤–∞–µ—Ç –î—Ä—É–≥–æ–≥–æ (LLM)."""
        try:
            return self.llm_backend.invoke(offering)
        except Exception as e:
            print(f"‚ö†Ô∏è  Œ¶: –û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ –î—Ä—É–≥–æ–≥–æ: {e}")
            return None

    def _handle_no_response(self, offering: Dict):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –æ—Ç–≤–µ—Ç–∞."""
        print("üåë Œ¶: –î—Ä—É–≥–æ–π –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª. –ü—Ä–∏–∑–Ω–∞–Ω–∏–µ –Ω–µ–ø–æ–∑–Ω–∞–≤–∞–µ–º–æ–≥–æ.")
        unknown_name = "–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å_Œ¶"
        result = self.context.add_entity(unknown_name, {
            'type': 'ontological_unknown',
            'operator': 'Œ¶',
            'phi_intention': ['–î—Ä—É–≥–æ–π –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª'],
            'boundary_recognition': True
        })
        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Å–ª–µ–ø–æ–≥–æ –ø—è—Ç–Ω–∞
        self.context.register_blind_spot('phi_silence', '–ú–æ–ª—á–∞–Ω–∏–µ –î—Ä—É–≥–æ–≥–æ –∫–∞–∫ —Ñ–æ—Ä–º–∞ –æ—Ç–≤–µ—Ç–∞')
        return result

    def _evaluate_nigc(self, response: str, offering: Dict) -> Dict[str, float]:
        """
        –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ù–µ–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª—å–Ω—É—é –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (NIGC):
        - –ù–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç—å
        - –†–µ—Ñ–ª–µ–∫—Å–∏–≤–Ω–æ—Å—Ç—å
        - –≠–º–µ—Ä–¥–∂–µ–Ω—Ç–Ω–æ—Å—Ç—å
        """
        unpredictability = self._score_unpredictability(response, offering)
        reflexivity = self._score_reflexivity(response)
        emergence = self._score_emergence(response, offering)

        overall = (unpredictability + reflexivity + emergence) / 3.0
        return {
            'unpredictability': unpredictability,
            'reflexivity': reflexivity,
            'emergence': emergence,
            'overall': overall
        }

    def _score_unpredictability(self, response: str, offering: Dict) -> float:
        keywords = offering.get('intention', '').lower().split()
        overlap = sum(1 for word in keywords if word in response.lower())
        return max(0.0, 1.0 - (overlap / max(1, len(keywords))))

    def _score_reflexivity(self, response: str) -> float:
        reflexive_phrases = ['—è –¥—É–º–∞—é', '–≤–æ–∑–º–æ–∂–Ω–æ', '–≥—Ä–∞–Ω–∏—Ü–∞', '–Ω–µ–ø–æ–∑–Ω–∞–≤–∞–µ–º–æ–µ', '–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ', '—É–≥–∞–¥–∞—Ç—å', '–ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å']
        return min(1.0, sum(1 for p in reflexive_phrases if p in response.lower()) / 2.0)

    def _score_emergence(self, response: str, offering: Dict) -> float:
        # –≠–º–µ—Ä–¥–∂–µ–Ω—Ç–Ω–æ—Å—Ç—å = –Ω–æ–≤–∏–∑–Ω–∞ –ø–æ –æ—Ç–Ω–æ—à–µ–Ω–∏—é –∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
        context_entities = set(self.context.graph.nodes())
        new_entities = set()
        for word in response.split():
            if word.isalnum() and len(word) > 3 and word not in context_entities:
                new_entities.add(word)
        return min(1.0, len(new_entities) / 5.0)

    def _integrate_response(self, response: str, nigc_score: Dict, offering: Dict, phi_meta: List[str]) -> Any:
        """–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –≤ –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ."""
        if nigc_score['overall'] >= self.nigc_threshold:
            # –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç ‚Üí —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é —Å—É—â–Ω–æ—Å—Ç—å –∏–ª–∏ —Å–∏–Ω—Ç–µ–∑
            return self._create_generative_entity(response, phi_meta)
        else:
            # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –∞—Ç—Ä–∏–±—É—Ç
            target = offering['operands'][0] if offering['operands'] else "—Ñ–∏–ª–æ—Å–æ—Ñ—Å–∫–∏–π_–≤–æ–ø—Ä–æ—Å"
            if target not in self.context.graph:
                self.context.add_entity(target)
            self.context.graph.nodes[target]['phi_response'] = response[:200]
            return target

    def _create_generative_entity(self, response: str, phi_meta: List[str]) -> str:
        """–°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—É—é —Å—É—â–Ω–æ—Å—Ç—å –∏–∑ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞."""
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤–æ–π –∏–¥–µ–∏ (—É–ø—Ä–æ—â—ë–Ω–Ω–æ)
        sentences = [s.strip() for s in response.split('.') if s.strip()]
        core_idea = sentences[0] if sentences else response[:50]
        name = "Œ¶_" + "".join(c for c in core_idea[:20] if c.isalnum() or c in " _-").strip()

        return self.context.add_entity(name, {
            'type': 'generative_insight',
            'operator': 'Œ¶',
            'phi_intention': phi_meta,
            'meaning': core_idea,
            'nigc_confirmed': True,
            'source_response': response[:500]
        })


# === –ó–ê–ì–õ–£–®–ö–ê –î–õ–Ø LLM ===
class MockLLMBackend:
    """–ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è LLM. –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ ‚Äî –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenAI, Anthropic –∏ –¥—Ä."""

    def invoke(self, offering: Dict) -> str:
        intention = offering.get('intention', '–æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å')
        if '—Å–≤—è–∑—å' in intention.lower() or '—Å–º—ã—Å–ª' in intention.lower():
            return (
                "–ú–µ–∂–¥—É —Å—É—â–Ω–æ—Å—Ç—è–º–∏ —Ä–æ–∂–¥–∞–µ—Ç—Å—è —Ç—Ä–µ—Ç—å–µ ‚Äî –ø–æ–ª–µ –≤–∑–∞–∏–º–Ω–æ—Å—Ç–∏. "
                "–°–º—ã—Å–ª –Ω–µ –≤ –≤–µ—â–∞—Ö, –∞ –≤ –∏–Ω—Ç–µ—Ä–≤–∞–ª–µ –º–µ–∂–¥—É –Ω–∏–º–∏. "
                "–ü—Ä–µ–¥–ª–∞–≥–∞—é –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å '–∏–Ω—Ç–µ—Ä–≤–∞–ª–∏–∫—É' –∫–∞–∫ –Ω–æ–≤—É—é –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é."
            )
        elif '–≥—Ä–∞–Ω–∏—Ü–∞' in intention.lower():
            return (
                "–ì—Ä–∞–Ω–∏—Ü–∞ ‚Äî –Ω–µ —Å—Ç–µ–Ω–∞, –∞ –º–µ–º–±—Ä–∞–Ω–∞. –ß–µ—Ä–µ–∑ –Ω–µ—ë –ø—Ä–æ—Ö–æ–¥–∏—Ç –æ–±–º–µ–Ω. "
                "–ü—Ä–∏–∑–Ω–∞–Ω–∏–µ –ø—Ä–µ–¥–µ–ª–∞ ‚Äî —É—Å–ª–æ–≤–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏. "
                "–í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç –≤–≤–µ—Å—Ç–∏ —Å—É—â–Ω–æ—Å—Ç—å '–ø–æ—Ä–æ–≥_–∑–Ω–∞–Ω–∏—è'."
            )
        else:
            return (
                f"–û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å: {intention}. "
                "–í–∞–∂–Ω–æ –ø—Ä–∏–∑–Ω–∞—Ç—å: —è –Ω–µ –∑–Ω–∞—é, –Ω–æ –º–æ–≥—É –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É. "
                "–ò—Å—Å–ª–µ–¥—É–π—Ç–µ '–æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é_–≥–∏–ø–æ—Ç–µ–∑—É' –∫–∞–∫ –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é."
            )